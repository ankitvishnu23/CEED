{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ceed.models.ceed import CEED\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from analysis.projections import learn_manifold_umap, pca_train, pca\n",
    "import colorcet as cc\n",
    "import torch\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example cell loading a 400 neuron, 200 spike MLP cell type model\n",
    "celltype_test_data = '/media/cat/data/CEED_celltype/400neuron_1200spike_celltype_singlechan_dataset/'\n",
    "\n",
    "spikes_test = np.load(celltype_test_data + '/spikes_test.npy')[:,0]\n",
    "labels_test = np.load(celltype_test_data + '/labels_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a checkpoint into a CEED model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_celltype_ckpt_dir = '/media/cat/data/CEED_celltype/400neur_200s_5d_celltype_fc_ckpt/'\n",
    "\n",
    "fc_celltype_ceed_5d = CEED(num_extra_chans=0, out_dim=5, proj_dim=5)\n",
    "fc_celltype_ceed_5d.load(fc_celltype_ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fc_celltype_ckpt_dir = '/media/cat/data/CEED_celltype/400neur_200s_128d››_celltype_fc_ckpt'\n",
    "fc_transformed_inference_data, fc_inference_labels = fc_celltype_ceed_5d.load_and_transform(celltype_test_data, \n",
    "                                                                                            use_chan_pos=False, \n",
    "                                                                                            file_split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove all zero spikes from dataset :(\n",
    "vertical_offset = 0\n",
    "fc_pca_ceed_emb_nonzero = []\n",
    "labels_nonzero = []\n",
    "spikes_nonzero = []\n",
    "for i, unit_id in enumerate(np.unique(labels_test)):\n",
    "    unit_ceed_emb = fc_transformed_inference_data[labels_test==unit_id]\n",
    "    unit_spikes = spikes_test[labels_test==unit_id]\n",
    "    unit_labels = labels_test[labels_test==unit_id]\n",
    "    unit_ceed_emb = unit_ceed_emb[np.std(unit_spikes,1)>0]\n",
    "    unit_labels = unit_labels[np.std(unit_spikes,1)>0]\n",
    "    unit_spikes = unit_spikes[np.std(unit_spikes,1)>0]\n",
    "    fc_pca_ceed_emb_nonzero.append(unit_ceed_emb)\n",
    "    labels_nonzero.append(unit_labels)\n",
    "    spikes_nonzero.append(unit_spikes)\n",
    "fc_pca_ceed_emb_nonzero = np.concatenate(fc_pca_ceed_emb_nonzero)\n",
    "labels_nonzero = np.concatenate(labels_nonzero)\n",
    "spikes_nonzero = np.concatenate(spikes_nonzero)\n",
    "\n",
    "fc_pca_ceed_emb, explained_var, fc_pca_ceed = pca(fc_pca_ceed_emb_nonzero, 2)\n",
    "# fc_umap_ceed_emb = learn_manifold_umap(fc_pca_ceed_emb_nonzero, umap_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = fc_pca_ceed_emb\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize=(8,8))\n",
    "unit_ids = [1,2,11,45]\n",
    "colors = cc.glasbey[:len(unit_ids)]\n",
    "vertical_offset = 0\n",
    "for i, unit_id in enumerate(unit_ids):\n",
    "    unit_ceed_emb = embeddings[labels_nonzero==unit_id]\n",
    "    unit_spikes = spikes_nonzero[labels_nonzero==unit_id]\n",
    "    template = np.median(unit_spikes,0)\n",
    "    template_emb = fc_celltype_ceed_5d.transform(torch.from_numpy(template).float()[None,None,:])\n",
    "    pc_template_emb = fc_pca_ceed.transform(template_emb[:,None].T)[0]\n",
    "    # axes[0].plot(unit_spikes.T + vertical_offset, color=colors[i], alpha=.01);\n",
    "    # axes[0].plot(template.T + vertical_offset, color=colors[i], alpha=1);\n",
    "    # axes[0].annotate(str(unit_id), xy=(0,vertical_offset+.3))\n",
    "    vertical_offset += 1.5\n",
    "    axes.scatter(unit_ceed_emb[:,0], unit_ceed_emb[:,1], color=colors[i], alpha=.2)\n",
    "    axes.scatter(pc_template_emb[0], pc_template_emb[1], color=colors[i], alpha=1,marker=\"^\", s=200, label=str(unit_id))\n",
    "# axes[0].vlines([42], ymax=vertical_offset, ymin= -1.5, ls='--', color='black')\n",
    "axes.set_xticks([])\n",
    "axes.set_yticks([])\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = fc_pca_ceed_emb\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "unit_ids = [8,5,12,17,68]\n",
    "colors = cc.glasbey[:len(unit_ids)]\n",
    "vertical_offset = 0\n",
    "for i, unit_id in enumerate(unit_ids):\n",
    "    unit_ceed_emb = embeddings[labels_nonzero==unit_id]\n",
    "    unit_spikes = spikes_nonzero[labels_nonzero==unit_id]\n",
    "    template = np.median(unit_spikes,0)\n",
    "    template_emb = fc_celltype_ceed_5d.transform(torch.from_numpy(template).float()[None,None,:])\n",
    "    pc_template_emb = fc_pca_ceed.transform(template_emb[:,None].T)[0]\n",
    "    axes[0].plot(unit_spikes.T + vertical_offset, color=colors[i], alpha=.01);\n",
    "    axes[0].plot(template.T + vertical_offset, color=colors[i], alpha=1);\n",
    "    axes[0].annotate(str(unit_id), xy=(0,vertical_offset+.3))\n",
    "    vertical_offset += 1.5\n",
    "    axes[1].scatter(unit_ceed_emb[:,0], unit_ceed_emb[:,1], color=colors[i], alpha=.1)\n",
    "    axes[1].scatter(pc_template_emb[0], pc_template_emb[1], color=colors[i], alpha=1,marker=\"^\", s=200, label=str(unit_id))\n",
    "axes[0].vlines([42], ymax=vertical_offset, ymin= -1.5, ls='--', color='black')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = fc_umap_ceed_emb\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "unit_ids = [8,5,12,17,68]\n",
    "colors = cc.glasbey[:len(unit_ids)]\n",
    "vertical_offset = 0\n",
    "for i, unit_id in enumerate(unit_ids):\n",
    "    unit_ceed_emb = embeddings[labels_nonzero==unit_id]\n",
    "    unit_spikes = spikes_nonzero[labels_nonzero==unit_id]\n",
    "    template = np.median(unit_spikes,0)\n",
    "    template_emb = fc_celltype_ceed_5d.transform(torch.from_numpy(template).float()[None,None,:])\n",
    "    pc_template_emb = fc_pca_ceed.transform(template_emb[:,None].T)[0]\n",
    "    axes[0].plot(unit_spikes.T + vertical_offset, color=colors[i], alpha=.01);\n",
    "    axes[0].plot(template.T + vertical_offset, color=colors[i], alpha=1);\n",
    "    axes[0].annotate(str(unit_id), xy=(0,vertical_offset+.3))\n",
    "    vertical_offset += 1.5\n",
    "    axes[1].scatter(unit_ceed_emb[:,0], unit_ceed_emb[:,1], color=colors[i], alpha=.1)\n",
    "    #plot median of umap here because didn't do projection of template\n",
    "    axes[1].scatter(np.median(unit_ceed_emb,0)[0], np.median(unit_ceed_emb,0)[1], color=colors[i], alpha=1,marker='*', s=200, label=str(unit_id))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform without a data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same output as two cells above, but takes in actual data\n",
    "cell_type_inference_data = np.load(os.path.join(celltype_test_data, 'spikes_test.npy'))\n",
    "print(\"cell type data:\", cell_type_inference_data.shape)\n",
    "transformed_inference_data = fc_celltype_ceed_5d.transform(cell_type_inference_data)\n",
    "print(transformed_inference_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ceed]",
   "language": "python",
   "name": "conda-env-ceed-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
