{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.data_gen_utils import download_IBL, extract_IBL, make_dataset, combine_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download IBL data to a location and destripe/process using the session's pid\n",
    "pid_sess1 = 'dab512bd-a02d-4c1f-8dbc-9155a163efc0'\n",
    "pid_sess2 = 'febb430e-2d50-4f83-87a0-b5ffbb9a4943'\n",
    "t_window = [0, 500]\n",
    "save_folder_sess1 = '/tmp1'\n",
    "save_folder_sess2 = '/tmp2'\n",
    "bin_file_sess1, meta_file_sess1 = download_IBL(pid=pid_sess1, t_window = t_window, save_folder=save_folder_sess1)\n",
    "bin_file_sess2, meta_file_sess2 = download_IBL(pid=pid_sess2, t_window = t_window, save_folder=save_folder_sess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the necessary spike index and other items to make a dataset\n",
    "spike_idx_sess1, geom_sess1, chan_idx_sess1, templates_sess1 = extract_IBL(bin_fp=bin_file_sess1, meta_fp=meta_file_sess1, pid=pid_sess1, t_window=t_window)\n",
    "spike_idx_sess2, geom_sess2, chan_idx_sess2, templates_sess2 = extract_IBL(bin_fp=bin_file_sess2, meta_fp=meta_file_sess2, pid=pid_sess2, t_window=t_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session 1 units to get data from and dataset save path\n",
    "selected_units_sess1 = [10, 20, 30]\n",
    "dataset_folder_sess1 = '/ds1'\n",
    "\n",
    "# make a dataset for training\n",
    "# will create a folder with the spike, probe channel number, and corresponding channel location datasets in the train, val, test splits\n",
    "# optionally also saves out spatial and temporal noise covariance matrices\n",
    "make_dataset(bin_path=bin_file_sess1, spike_index=spike_idx_sess1, geom=geom_sess1, save_path=dataset_folder_sess1, chan_index=chan_idx_sess1, \n",
    "             templates=templates_sess1, unit_ids=selected_units_sess1, train_num=200, val_num=0, test_num=200, save_covs=True,\n",
    "             num_chans_extract=21, plot=False, normalize=False, shift=False, do_split=True,\n",
    "             save_var_num=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_units_sess2 = [100, 110, 120]\n",
    "dataset_folder_sess2 = '/ds2'\n",
    "\n",
    "# make dataset 2 for training\n",
    "make_dataset(bin_path=bin_file_sess2, spike_index=spike_idx_sess2, geom=geom_sess2, save_path=dataset_folder_sess2, chan_index=chan_idx_sess2, \n",
    "             templates=templates_sess2, unit_ids=selected_units_sess2, train_num=200, val_num=0, test_num=200, save_covs=True,\n",
    "             num_chans_extract=21, plot=False, normalize=False, shift=False, do_split=True, \n",
    "             save_var_num=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds_path = '/combined'\n",
    "\n",
    "# combine the two training datasets into a larger one for more unit diversity\n",
    "combine_datasets(dataset_folder_sess1, dataset_folder_sess2, combined_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ds_path = '/inference'\n",
    "selected_units_inf = [200, 210, 220]\n",
    "\n",
    "# make a dataset for spike sorting inference\n",
    "# will save out only spikes, channel numbers, and channel locations for a spikes test set (only pass in test_num)\n",
    "# save_var_num flag will allow units with < test_num spikes in the recording to be saved out in the test set as well (change to min and max spikes)\n",
    "# for cell type datasets the normalize Flag can be set to True\n",
    "make_dataset(bin_path=bin_file_sess1, spike_index=spike_idx_sess1, geom=geom_sess1, save_path=inference_ds_path, chan_index=chan_idx_sess1, \n",
    "             templates=templates_sess1, unit_ids=selected_units_inf, test_num=200, save_covs=True,\n",
    "             num_chans_extract=21, do_data_split=False, normalize=False, save_var_num=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
