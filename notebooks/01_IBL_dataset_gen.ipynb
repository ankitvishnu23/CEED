{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from analysis.data_gen_utils import download_IBL, extract_IBL, make_dataset, combine_datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and destripe AP data from an IBL session by its PID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pid_sess1 = 'dab512bd-a02d-4c1f-8dbc-9155a163efc0'\n",
    "pid_sess2 = 'febb430e-2d50-4f83-87a0-b5ffbb9a4943'\n",
    "save_folder_sess1 = '/media/cat/data/IBL_data_CEED/dab512bd-a02d-4c1f-8dbc-9155a163efc0_test'\n",
    "save_folder_sess2 = '/media/cat/data/IBL_data_CEED/febb430e-2d50-4f83-87a0-b5ffbb9a4943_test'\n",
    "t_window = [0, 200] #in seconds\n",
    "bin_file_sess1, meta_file_sess1 = download_IBL(pid=pid_sess1, t_window=t_window, save_folder=save_folder_sess1, overwrite=True)\n",
    "bin_file_sess2, meta_file_sess2 = download_IBL(pid=pid_sess2, t_window=t_window, save_folder=save_folder_sess2, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''extract the all data needed to make CEED dataset\n",
    "spike_idx_sess: spike_times, channels, neurons (if use_labels=True)\n",
    "geom_sess: channels x 2\n",
    "chan_idx_sess: waveform extraction channels for each channel\n",
    "templates_sess: templates across all channels for all neurons\n",
    "'''\n",
    "recompute = True\n",
    "\n",
    "if recompute:\n",
    "    spike_idx_sess1, geom_sess1, chan_idx_sess1, templates_sess1 = extract_IBL(bin_fp=bin_file_sess1, \n",
    "                                                                               meta_fp=meta_file_sess1, \n",
    "                                                                               pid=pid_sess1, t_window=t_window, \n",
    "                                                                               use_labels=True)\n",
    "    spike_idx_sess2, geom_sess2, chan_idx_sess2, templates_sess2 = extract_IBL(bin_fp=bin_file_sess2, \n",
    "                                                                               meta_fp=meta_file_sess2, \n",
    "                                                                               pid=pid_sess2, t_window=t_window,\n",
    "                                                                               use_labels=True)\n",
    "else:\n",
    "    spike_idx_sess1 = np.load('spike_idx_sess1.npy')\n",
    "    geom_sess1 = np.load('geom_sess1.npy')\n",
    "    chan_idx_sess1 = np.load('chan_idx_sess1.npy')\n",
    "    templates_sess1 = np.load('templates_sess1.npy')\n",
    "    spike_idx_sess2 = np.load('spike_idx_sess2.npy')\n",
    "    geom_sess2 = np.load('geom_sess2.npy')\n",
    "    chan_idx_sess2 = np.load('chan_idx_sess2.npy')\n",
    "    templates_sess2 = np.load('templates_sess2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot a template on the 40 extracted channels (not all 40 used to train CEED).\n",
    "template_id = 17\n",
    "plt.plot(templates_sess1[template_id][:,chan_idx_sess1[template_id]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fewer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session 1 units to get data from and dataset save path\n",
    "selected_units_sess1 = [200, 210, 220]#np.arange(200)\n",
    "dataset_folder_sess1 = save_folder_sess1 + '/ds'\n",
    "\n",
    "# make a dataset for training\n",
    "# will create a folder with the spike, probe channel number, and corresponding channel location datasets in the train, val, test splits\n",
    "# optionally also saves out spatial and temporal noise covariance matrices\n",
    "train_set1, val_set1, test_set1, train_geom_locs1, val_geom_locs1, \\\n",
    "test_geom_locs1, train_max_chan1, val_max_chan1, test_max_chan1 = make_dataset(bin_path=bin_file_sess1, spike_index=spike_idx_sess1,\n",
    "                                                                               geom=geom_sess1, save_path=dataset_folder_sess1, \n",
    "                                                                               chan_index=chan_idx_sess1, templates=templates_sess1, \n",
    "                                                                               unit_ids=selected_units_sess1, train_num=200, val_num=0, \n",
    "                                                                               test_num=200, save_covs=False, num_chans_extract=21, \n",
    "                                                                               plot=False, normalize=False, shift=False, inference=False,\n",
    "                                                                               save_fewer=save_fewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session 1 units to get data from and dataset save path\n",
    "selected_units_sess2 = [200, 210, 220]#np.arange(200)\n",
    "dataset_folder_sess2 = save_folder_sess2 + '/ds'\n",
    "\n",
    "# make a dataset for training\n",
    "# will create a folder with the spike, probe channel number, and corresponding channel location datasets in the train, val, test splits\n",
    "# optionally also saves out spatial and temporal noise covariance matrices\n",
    "train_set2, val_set2, test_set2, train_geom_locs2, val_geom_locs2, \\\n",
    "test_geom_locs2, train_max_chan2, val_max_chan2, test_max_chan2 = make_dataset(bin_path=bin_file_sess2, spike_index=spike_idx_sess2,\n",
    "                                                                               geom=geom_sess2, save_path=dataset_folder_sess2, \n",
    "                                                                               chan_index=chan_idx_sess2, templates=templates_sess2, \n",
    "                                                                               unit_ids=selected_units_sess2, train_num=200, val_num=0, \n",
    "                                                                               test_num=200, save_covs=False, num_chans_extract=21, \n",
    "                                                                               plot=False, normalize=False, shift=False, inference=False,\n",
    "                                                                               save_fewer=save_fewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds_path = '/media/cat/data/IBL_data_CEED/combined'\n",
    "\n",
    "# combine the two training datasets into a larger one for more unit diversity\n",
    "dataset_list = [dataset_folder_sess1, dataset_folder_sess2]\n",
    "combine_datasets(dataset_list, combined_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_ds_path = save_folder_sess1 + '/inference'\n",
    "selected_units_inf = [200, 210, 220]\n",
    "\n",
    "# make a dataset for spike sorting inference\n",
    "# will save out only spikes, channel numbers, and channel locations for a spikes test set (only pass in test_num)\n",
    "# save_var_num flag will allow units with < test_num spikes in the recording to be saved out in the test set as well (change to min and max spikes)\n",
    "# for cell type datasets the normalize Flag can be set to True\n",
    "test_set, test_geom_locs, test_max_chan = make_dataset(bin_path=bin_file_sess1, spike_index=spike_idx_sess1, \n",
    "                                                       geom=geom_sess1, save_path=inference_ds_path, \n",
    "                                                       chan_index=chan_idx_sess1, templates=templates_sess1, \n",
    "                                                       unit_ids=selected_units_inf, test_num=200, save_covs=False,\n",
    "                                                       num_chans_extract=21, normalize=False, save_fewer=save_fewer, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spikes_test = np.load(save_folder_sess1 + '/ds/spikes_test.npy') \n",
    "labels_test = np.load(save_folder_sess1 + '/ds/labels_test.npy') \n",
    "channel_num_test = np.load(save_folder_sess1 + '/ds/channel_num_test.npy') \n",
    "channel_spike_locs_test = np.load(save_folder_sess1 + '/ds/channel_spike_locs_test.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ceed]",
   "language": "python",
   "name": "conda-env-ceed-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
